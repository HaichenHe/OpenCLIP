seed: 1024
data:
    dataset: ucf101
    modality: video
    num_segments: 8
    seg_length: 8
    batch_size: 32
    workers: 8
    num_classes: 101
    image_tmpl: 'image_{:05}.jpg'
    val_root: '/opt/data/private/hhc/recognition/Datasets/ucf101/videos'
    val_list: '/opt/data/private/hhc/OpenCLIP/lists/ucf101/video/ucf_full_for_zeroshot.txt' 
    label_list: 'lists/ucf101/ucf_labels.csv'
    index_bias: 1
    input_size: 224
network:
    arch: ViT-B/16 
    model_name:  BasicClip
    temporal_type: None #TemporalTransformer
    init: True
    drop_out: 0.0
    emb_dropout: 0.0 
solver:
    num_gpus: 1
logging:
    print_freq: 10
    eval_freq: 1