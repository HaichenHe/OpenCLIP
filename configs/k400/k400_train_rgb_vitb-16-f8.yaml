resume:
pretrain:
seed: 1024
data:
    dataset: k400
    modality: video
    num_segments: 8
    seg_length: 1
    batch_size: 64
    workers: 8
    num_classes: 400
    image_tmpl: 'img_{:05d}.jpg'
    train_root: '/opt/data/private/hhc/recognition/Datasets/kinetics400/train'
    train_list: '/opt/data/private/hhc/recognition/Datasets/kinetics400/datalist/kinetics_video_train.txt'
    val_root: '/opt/data/private/hhc/recognition/Datasets/kinetics400/val'
    val_list: '/opt/data/private/hhc/recognition/Datasets/kinetics400/datalist/kinetics_video_val.txt'
    label_list: '/opt/data/private/hhc/recognition/Datasets/kinetics400/datalist/labels.csv'
    input_size: 224
    random_shift: True
network:
    arch: ViT-B/16  #ViT-B/32 ViT-B/16
    model_name:  BasicClip
    temporal_type: TemporalTransformer
    init: True
    tm: False
    drop_out: 0.0 
    emb_dropout: 0.0 
    joint_st: False
    drop: 0           
    fix_text: True  
    fix_video: False
solver:
    type: cosine
    epochs: 30
    start_epoch: 0
    epoch_offset: 0
    optim: adamw
    lr: 5.e-5
    lr_warmup_step: 5
    weight_decay: 0.2
    loss_type: cross_entropy
    evaluate: False
    clip_ratio: 0.1
    grad_accumulation_steps: 1
    num_gpus: 1
logging:
    print_freq: 10
    eval_freq: 1